{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/afolabiadeshola/Downloads/dsp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "['id', 'tap_id', 'useragent', 'ip_address', 'device_model', 'device_manufacturer', 'device_type', 'os_vendor', 'os_name', 'os_version', 'os_sub_version', 'browser_name', 'browser_version', 'location_continent', 'location_region', 'location_country', 'location_state', 'location_zip_code', 'user_id', 'ifa', 'dpifmd5', 'google_id', 'dsp_id', 'app_id', 'app_name', 'publisher_id', 'publisher_name', 'publisher_url', 'site_id', 'site_name', 'domain', 'referrer_url', 'site_link', 'data_type', 'exchange', 'carrier', '@source', 'captured_time', '@timestamp', 'source_type', 'device_screen_height', 'device_screen_width', 'device_screen_pixel_ratio', 'device_idfa', 'category', 'ad_id', 'win_price', 'campaign_id', 'campaign_name', 'campaign_type', 'campaign_level', 'campaign_status', 'campaign_flag', 'campaign_ad_type', 'cdn_flag', 'media_id', 'media_ad_url', 'media_type', 'media_level', 'media_status', 'media_flag', 'media_ad_id', 'media_ad_name', 'media_ad_width', 'media_ad_height', 'media_ad_format', 'campaign_ad_domain', 'video_flag', 'campaign_landing_url']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as f:\n",
    "    names = f.readline()\n",
    "cols = names.rstrip('\\n').split(',')\n",
    "drop_quotes = [column.replace('\"', '') for column in cols]\n",
    "print (len(drop_quotes))\n",
    "print(drop_quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 69 columns in total. There are alot of columns with NaN values. The idea is to exclude columns with at least 80% NaN values. The cells below also separate each of the columns based on its relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "totally_nan_columns =  ['os_sub_version','location_zip_code','publisher_name','publisher_url','domain','referrer_url','device_idfa','category','cdn_flag','media_id','media_ad_url','media_type','media_level','media_status','media_flag','media_ad_id','media_ad_name','media_ad_width','media_ad_height','media_ad_format','campaign_ad_domain','video_flag','campaign_landing_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = [col for col in drop_quotes if col not in totally_nan_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'tap_id',\n",
       " 'useragent',\n",
       " 'ip_address',\n",
       " 'device_model',\n",
       " 'device_manufacturer',\n",
       " 'device_type',\n",
       " 'os_vendor',\n",
       " 'os_name',\n",
       " 'os_version',\n",
       " 'browser_name',\n",
       " 'browser_version',\n",
       " 'location_continent',\n",
       " 'location_region',\n",
       " 'location_country',\n",
       " 'location_state',\n",
       " 'user_id',\n",
       " 'ifa',\n",
       " 'dpifmd5',\n",
       " 'google_id',\n",
       " 'dsp_id',\n",
       " 'app_id',\n",
       " 'app_name',\n",
       " 'publisher_id',\n",
       " 'site_id',\n",
       " 'site_name',\n",
       " 'site_link',\n",
       " 'data_type',\n",
       " 'exchange',\n",
       " 'carrier',\n",
       " '@source',\n",
       " 'captured_time',\n",
       " '@timestamp',\n",
       " 'source_type',\n",
       " 'device_screen_height',\n",
       " 'device_screen_width',\n",
       " 'device_screen_pixel_ratio',\n",
       " 'ad_id',\n",
       " 'win_price',\n",
       " 'campaign_id',\n",
       " 'campaign_name',\n",
       " 'campaign_type',\n",
       " 'campaign_level',\n",
       " 'campaign_status',\n",
       " 'campaign_flag',\n",
       " 'campaign_ad_type']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = ['id', 'tap_id', 'user_id', 'google_id','dsp_id', 'app_id', 'publisher_id', 'site_id', 'ad_id', 'campaign_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_relevant = ['ip_address', 'useragent', '@source', 'source_type', 'location_continent', 'location_country', '@timestamp', 'win_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_sure = ['dpifmd5', 'ifa', 'campaign_ad_type', 'campaign_name','campaign_type', 'campaign_level', 'campaign_status', 'campaign_flag', 'device_model', 'device_manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['data_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [col for col in needed_columns if col not in list(np.concatenate((IDs, not_relevant, not_sure)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['device_type',\n",
       " 'os_vendor',\n",
       " 'os_name',\n",
       " 'os_version',\n",
       " 'browser_name',\n",
       " 'browser_version',\n",
       " 'location_region',\n",
       " 'location_state',\n",
       " 'app_name',\n",
       " 'site_name',\n",
       " 'site_link',\n",
       " 'data_type',\n",
       " 'exchange',\n",
       " 'carrier',\n",
       " 'captured_time',\n",
       " 'device_screen_height',\n",
       " 'device_screen_width',\n",
       " 'device_screen_pixel_ratio']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nan = ['os_name', 'browser_name', 'location_region', 'location_state', 'app_name', 'site_name', 'site_link', 'carrier', 'inventory', 'os_vendor', 'os_version', 'browser_version', 'os_name_version', 'browser_name_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columms = ['device_screen_height', 'device_screen_width', 'device_screen_pixel_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_attr = ['os_name_version', 'browser_name_version', 'inventory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'Bid':0,'Click':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_columns = ['os_name', 'os_version', 'browser_name', 'browser_version', 'app_name', 'site_name', 'site_link', 'captured_time', 'data_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA EXPLORATION ON A SAMPLE SIZE OF 300K ROWS. WHATEVER INFERENCE GOTTEN FROM HERE WOULD BE USED TO GENERALIZE. TOTAL NUMBER OF ROWS IN THE DOCUMENT IS 1028856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (29,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/afolabiadeshola/Downloads/dsp.csv\", usecols=train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea here is to add the app_name and site_name together to have a singular column inventory\n",
    "def inventory(data,column1= 'app_name', column2 = 'site_name'):\n",
    "    data['inventory'] = data[column1].replace(np.nan,'')+ data[column2].replace(np.nan,'')\n",
    "    data['inventory'] = data['inventory'].replace('',np.nan)\n",
    "#The split function gets the site_name from site link and helps reduce the Nan values \n",
    "def split(data,column1,column2):\n",
    "    data[column2] = data[column1].str.split('/', expand = True)[2]\n",
    "#A lot of columns were missing for region. The states column had less missing value. Since each state belong to a geographical region, it made sense to map them accordingly\n",
    "def replace_region(data):\n",
    "    region = data['location_state']\n",
    "    if region in ['Benue','Kogi','Kwara','Nasarawa','Niger','Plateau','Abuja','Makurdi','Lokoja','Asokoro']:\n",
    "        return 'North_Central'\n",
    "    elif region in ['Adamawa','Bauchi','Borno','Gombe','Taraba','Yobe','Jos','Minna','Maiduguri','Yola']:\n",
    "        return 'North_East'\n",
    "    elif region in ['Jigawa','Kaduna','Kano','Katsina','Kebbi','Sokoto','Zamfara','Zaria','Dutse']:\n",
    "        return 'North_West'\n",
    "    elif region in ['Abia','Anambra','Ebonyi','Enugu','Imo','Abakaliki','Owerri','Umuahia']:\n",
    "        return 'South_East'\n",
    "    elif region in ['Akwa Ibom','Cross River','Bayelsa','Rivers','Delta','Edo','Benin City','Port Harcourt','Asaba',\n",
    "                   'Warri','Nsukka','Calabar','Uyo','Yenagoa','Eket','Sagbama','Bonny','Effurun']:\n",
    "        return 'South_South'\n",
    "    elif region in ['Ekiti','Lagos','Ogun','Ondo','Osun','Oyo','Ikeja','Ikire','Badagri','Ikorodu','Ibadan',\n",
    "                   'Suleja','Ilorin','Abeokuta','Osogbo','Akure','Ede','Ikotun','Lekki','Ikoyi','Ota','Ojota',\n",
    "                   'Sagamu','Ogudu','Mowe','Agege','Omu-Aran','Aponri']:\n",
    "        return 'South_West'\n",
    "#This function takes care of missing values in the os_vendor column. Values from os_name can be used to fix this.\n",
    "def replace_vendor(os_name,os_vendor):\n",
    "    if 'Macintosh' in str(os_name):\n",
    "        return 'Apple'\n",
    "    elif 'X11' in str(os_name):\n",
    "        return 'Microsoft'\n",
    "    else:\n",
    "        return os_vendor\n",
    "#This cleans the time column and separates each value into day, hour and minute \n",
    "def clean_time(value):\n",
    "    value = value.replace('T', ' ')\n",
    "    value = value[:19]\n",
    "    return value\n",
    "def process_time(df):\n",
    "    df['captured_time'] = df['captured_time'].apply(lambda x:clean_time(x))\n",
    "    df['captured_time'] = pd.to_datetime(df['captured_time'])\n",
    "    df['day'] = df['captured_time'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['captured_time'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['captured_time'].dt.minute.astype('uint8')\n",
    "#This functions clear Nans and replaces them with others for categorical variables and replaces numerical variables with the mean\n",
    "def clear_nan(data):\n",
    "    for item in columns_with_nan:\n",
    "        data[item] = data[item].fillna(\"Others\")\n",
    "def clear_nan_numeric(data):\n",
    "    for item in numerical_columms:\n",
    "        data[item] = data[item].fillna(data[item].mean())\n",
    "#This function picks top 50 values in a column and replaces every other value with others    \n",
    "# def pick_top_attr(data):\n",
    "#     for item in top_attr:\n",
    "#         top_val = list(data[item].value_counts()[:50].index)\n",
    "#         data[item] = data[item].apply(lambda x : x if x in top_val else \"other\")\n",
    "#This is a general cleanup function. Converts columns to strings and joins columns together based on relevance.\n",
    "def column_cleanup(data):\n",
    "    data['y'] = data['data_type'].map(dictionary)\n",
    "    data['os_version'] = data.os_version.astype(str)\n",
    "    data['browser_version'] = data.browser_version.astype(str)\n",
    "    data['location_region'] = data.apply(lambda x: replace_region(x), axis=1)\n",
    "    data['os_vendor'] = data.apply(lambda x: replace_vendor(x['os_name'], x['os_vendor']), axis=1)\n",
    "    data['os_name_version'] = data['os_name'] + data['os_version']\n",
    "    data['browser_name_version'] = data['browser_name'] + data['browser_version']\n",
    "\n",
    "def preprocessing_file(data):    \n",
    "    process_time(data)\n",
    "    split(data, 'site_link', 'site_name')\n",
    "    inventory(data)\n",
    "    column_cleanup(data)\n",
    "    clear_nan_numeric(data)\n",
    "    clear_nan(data) \n",
    "    #pick_top_attr(data)\n",
    "    training_data = data.drop(joined_columns, axis=1)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = preprocessing_file(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_type</th>\n",
       "      <th>os_vendor</th>\n",
       "      <th>location_region</th>\n",
       "      <th>location_state</th>\n",
       "      <th>exchange</th>\n",
       "      <th>carrier</th>\n",
       "      <th>device_screen_height</th>\n",
       "      <th>device_screen_width</th>\n",
       "      <th>device_screen_pixel_ratio</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>inventory</th>\n",
       "      <th>y</th>\n",
       "      <th>os_name_version</th>\n",
       "      <th>browser_name_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Google</td>\n",
       "      <td>South_West</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>adx</td>\n",
       "      <td>/54</td>\n",
       "      <td>604.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>Smart Scan ��� PDF Scanner, Free files Scanning</td>\n",
       "      <td>1</td>\n",
       "      <td>android6.0</td>\n",
       "      <td>Chrome Mobile WebView75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Google</td>\n",
       "      <td>South_West</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>adx</td>\n",
       "      <td>/</td>\n",
       "      <td>602.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>AppLock - Lock Apps, PIN u0026 Pattern Lock</td>\n",
       "      <td>1</td>\n",
       "      <td>android7.0</td>\n",
       "      <td>Chrome Mobile WebView58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Google</td>\n",
       "      <td>South_West</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>adx</td>\n",
       "      <td>/</td>\n",
       "      <td>570.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>skpoints.com</td>\n",
       "      <td>1</td>\n",
       "      <td>android6.0</td>\n",
       "      <td>Chrome Mobile55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Google</td>\n",
       "      <td>South_West</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>adx</td>\n",
       "      <td>/54</td>\n",
       "      <td>640.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>Emoji Launcher - Stickers u0026 Themes</td>\n",
       "      <td>1</td>\n",
       "      <td>android4.4.4</td>\n",
       "      <td>Chrome Mobile30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Google</td>\n",
       "      <td>South_West</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>adx</td>\n",
       "      <td>/54</td>\n",
       "      <td>640.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>Proposal u0026 Surat Perjanjian</td>\n",
       "      <td>1</td>\n",
       "      <td>android7.0</td>\n",
       "      <td>Chrome Mobile WebView64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  device_type os_vendor location_region location_state exchange carrier  device_screen_height  device_screen_width  device_screen_pixel_ratio  day  hour  minute                                        inventory  y os_name_version       browser_name_version\n",
       "0  Phone       Google    South_West      Lagos          adx      /54     604.0                 360.0                3.0                        22   13    44      Smart Scan ��� PDF Scanner, Free files Scanning  1  android6.0      Chrome Mobile WebView75.0\n",
       "1  Phone       Google    South_West      Lagos          adx      /       602.0                 360.0                3.0                        22   14    47      AppLock - Lock Apps, PIN u0026 Pattern Lock      1  android7.0      Chrome Mobile WebView58.0\n",
       "2  Phone       Google    South_West      Lagos          adx      /       570.0                 320.0                1.5                        22   14    56      skpoints.com                                     1  android6.0      Chrome Mobile55.0        \n",
       "3  Phone       Google    South_West      Lagos          adx      /54     640.0                 360.0                2.0                        22   15    17      Emoji Launcher - Stickers u0026 Themes           1  android4.4.4    Chrome Mobile30.0        \n",
       "4  Phone       Google    South_West      Lagos          adx      /54     640.0                 360.0                2.0                        22   17    14      Proposal u0026 Surat Perjanjian                  1  android7.0      Chrome Mobile WebView64.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "category_dict = {}\n",
    "def attribute(data,category_dict=None):\n",
    "    config = yaml.safe_load(open(\"/Users/afolabiadeshola/Downloads/features.yml\"))\n",
    "    cat_attributes = config['cat_attributes']\n",
    "    for attribute in cat_attributes:\n",
    "        if attribute not in category_dict:\n",
    "            category_dict[attribute] = set()\n",
    "        category_dict[attribute].update(data[attribute].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute(final_data, category_dict=category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "for category in category_dict.keys():\n",
    "    categories.append(list(category_dict[category]))\n",
    "    print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('one_hot_encoding', OneHotEncoder(handle_unknown = \"ignore\", categories = categories)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_data(training_data):\n",
    "    \n",
    "#     num_attributes = training_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#     num_attributes.remove(\"y\")\n",
    "\n",
    "#     cat_attributes = training_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "#     full_pipeline = ColumnTransformer([\n",
    "#             (\"num\", num_pipeline, num_attributes),\n",
    "#             (\"cat\", cat_pipeline, cat_attributes),\n",
    "#         ])\n",
    "    \n",
    "#     X_raw = training_data.drop(\"y\", axis=1)\n",
    "#     y_r = training_data[\"y\"].copy()\n",
    "    \n",
    "#     full_pipeline.fit(X_raw)\n",
    "    \n",
    "#     X_train_raw, X_cv_raw, y_train, y_cv = train_test_split(X_raw, y_r, test_size=0.2, stratify = y_r)\n",
    "    \n",
    "#     X_train = full_pipeline.transform(X_train_raw)\n",
    "#     X_cv = full_pipeline.transform(X_cv_raw)\n",
    "    \n",
    "#     print(f\"Clicks in Training Set =>  {np.sum(y_train == 1)} , in CV =>  {np.sum(y_cv == 1)}\") \n",
    "#     print(f\"SMS in Training Set =>  {np.sum(y_train == 0)} , in CV =>  {np.sum(y_cv == 0)}\")\n",
    "    \n",
    "#     names = [\"Extra Trees\", \"Random Forest\", \"KNeighbors\",\"Logistic\",\n",
    "#          \"Naive Bayes\", \"Decision Tree\",\"Support Vector Machine\"]\n",
    "#     classifiers = [\n",
    "#     ExtraTreesClassifier(n_estimators=200,criterion = 'entropy'),\n",
    "#     RandomForestClassifier(n_estimators=200,criterion = 'entropy'),\n",
    "#     KNeighborsClassifier(),\n",
    "#     LogisticRegression(),\n",
    "#     GaussianNB(),\n",
    "#     DecisionTreeClassifier(criterion='entropy'),\n",
    "#     SVC(kernel = 'rbf')\n",
    "#     ]\n",
    "\n",
    "#     i=0\n",
    "#     f1_results=[]\n",
    "#     acc_results=[]\n",
    "#     for classifier in classifiers:\n",
    "#         print(names[i])\n",
    "#         classifier.fit(X_train, y_train)\n",
    "#         y_pred = classifier.predict(X_cv)\n",
    "#         f1score=f1_score(y_cv,y_pred)\n",
    "#         accuracy=accuracy_score(y_cv,y_pred)\n",
    "#         print(\"F1 Score:\",f1score)\n",
    "#         print(\"Accuracy Score:\",accuracy)\n",
    "#         f1_results.append(f1score)\n",
    "#         acc_results.append(accuracy)\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_wide_model():\n",
    "    #inputs = tf.keras.Input(shape=X_train.shape[1:])\n",
    "    inputs = tf.keras.Input(shape=(1906,))\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    deep_output = layers.Dense(1)(x)\n",
    "\n",
    "    wide_output = layers.Dense(1)(inputs)\n",
    "    total_output = layers.add([deep_output, wide_output])\n",
    "    output = layers.Dense(1, activation= 'sigmoid')(total_output)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, output, name='wide_and_deep') \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "metrics = [tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "           tf.keras.metrics.FalsePositives(name='fp'),\n",
    "           tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "           tf.keras.metrics.TruePositives(name='tp'),\n",
    "           tf.keras.metrics.Precision(name='precision'),\n",
    "           tf.keras.metrics.Recall(name='recall')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_model = get_wide_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "logdir = os.path.join(\"/Users/afolabiadeshola/Documents/DSP\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_and_deep\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1906)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          244096      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1907        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 279,158\n",
      "Trainable params: 279,158\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wide_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote_algo = SMOTE(random_state=0)\n",
    "# smote_data_X,smote_data_Y = smote_algo.fit_sample(X_train, y_train)\n",
    "# smote_data_X = pd.DataFrame(data=smote_data_X,columns=X_train.columns)\n",
    "# smote_data_Y= pd.DataFrame(data=smote_data_Y,columns=[\"y\"])\n",
    "\n",
    "# X_train  = smote_data_X\n",
    "# y_train  = smote_data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_whole(df):\n",
    "    \n",
    "    num_attributes = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_attributes.remove(\"y\")\n",
    "\n",
    "    cat_attributes = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attributes),\n",
    "            (\"cat\", cat_pipeline, cat_attributes),\n",
    "        ])\n",
    "    \n",
    "    X_raw = df.drop(\"y\", axis=1)\n",
    "    y_r = df[\"y\"].copy()\n",
    "    \n",
    "    full_pipeline.fit(X_raw)\n",
    "    \n",
    "    X_train_raw, X_cv_raw, y_train, y_cv = train_test_split(X_raw, y_r, test_size=0.2, stratify = y_r)\n",
    "    \n",
    "    X_train = full_pipeline.transform(X_train_raw)\n",
    "    X_cv = full_pipeline.transform(X_cv_raw)\n",
    "    \n",
    "#     smote_algo = SMOTE(random_state=0)\n",
    "#     smote_data_X,smote_data_Y = smote_algo.fit_sample(X_train, y_train)\n",
    "#     smote_data_X = pd.DataFrame(data=smote_data_X,columns=X_train_raw.columns)\n",
    "#     smote_data_Y= pd.DataFrame(data=smote_data_Y,columns=[\"y\"])\n",
    "\n",
    "#     X_train  = smote_data_X\n",
    "#     y_train  = smote_data_Y\n",
    "    \n",
    "    \n",
    "    print(f\"Clicks in Training Set =>  {np.sum(y_train == 1)} , in CV =>  {np.sum(y_cv == 1)}\") \n",
    "    print(f\"SMS in Training Set =>  {np.sum(y_train == 0)} , in CV =>  {np.sum(y_cv == 0)}\") \n",
    "    print (X_train.shape[1:])\n",
    "    weight_for_0 = 1. / np.sum(y_train == 0)\n",
    "    weight_for_1 = 1. / np.sum(y_train == 1)\n",
    "    \n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "    wide_model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(X_cv, y_cv),\n",
    "          callbacks = [tensorboard_callback],         \n",
    "          class_weight=class_weight)\n",
    "    score = wide_model.evaluate(X_cv, y_cv, verbose=0)\n",
    "    predictions = wide_model.predict(X_cv)\n",
    "    return wide_model\n",
    "    print (predictions)        \n",
    "    print('Validation Metrics    :', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks in Training Set =>  1486 , in CV =>  372\n",
      "SMS in Training Set =>  821598 , in CV =>  205399\n",
      "(1906,)\n",
      "Train on 823084 samples, validate on 205771 samples\n",
      "Epoch 1/10\n",
      "823084/823084 - 34s - loss: 1.1744e-06 - fn: 319.0000 - fp: 192548.0000 - tn: 629050.0000 - tp: 1167.0000 - precision: 0.0060 - recall: 0.7853 - val_loss: 0.4253 - val_fn: 43.0000 - val_fp: 41758.0000 - val_tn: 163641.0000 - val_tp: 329.0000 - val_precision: 0.0078 - val_recall: 0.8844\n",
      "Epoch 2/10\n",
      "823084/823084 - 54s - loss: 8.3857e-07 - fn: 175.0000 - fp: 129476.0000 - tn: 692122.0000 - tp: 1311.0000 - precision: 0.0100 - recall: 0.8822 - val_loss: 0.2881 - val_fn: 55.0000 - val_fp: 26012.0000 - val_tn: 179387.0000 - val_tp: 317.0000 - val_precision: 0.0120 - val_recall: 0.8522\n",
      "Epoch 3/10\n",
      "823084/823084 - 52s - loss: 7.6286e-07 - fn: 153.0000 - fp: 117007.0000 - tn: 704591.0000 - tp: 1333.0000 - precision: 0.0113 - recall: 0.8970 - val_loss: 0.3009 - val_fn: 53.0000 - val_fp: 25317.0000 - val_tn: 180082.0000 - val_tp: 319.0000 - val_precision: 0.0124 - val_recall: 0.8575\n",
      "Epoch 4/10\n",
      "823084/823084 - 53s - loss: 7.2369e-07 - fn: 147.0000 - fp: 116273.0000 - tn: 705325.0000 - tp: 1339.0000 - precision: 0.0114 - recall: 0.9011 - val_loss: 0.3156 - val_fn: 44.0000 - val_fp: 26325.0000 - val_tn: 179074.0000 - val_tp: 328.0000 - val_precision: 0.0123 - val_recall: 0.8817\n",
      "Epoch 5/10\n",
      "823084/823084 - 50s - loss: 6.9836e-07 - fn: 140.0000 - fp: 118478.0000 - tn: 703120.0000 - tp: 1346.0000 - precision: 0.0112 - recall: 0.9058 - val_loss: 0.2780 - val_fn: 43.0000 - val_fp: 26464.0000 - val_tn: 178935.0000 - val_tp: 329.0000 - val_precision: 0.0123 - val_recall: 0.8844\n",
      "Epoch 6/10\n",
      "823084/823084 - 51s - loss: 6.8637e-07 - fn: 130.0000 - fp: 115340.0000 - tn: 706258.0000 - tp: 1356.0000 - precision: 0.0116 - recall: 0.9125 - val_loss: 0.3252 - val_fn: 42.0000 - val_fp: 27031.0000 - val_tn: 178368.0000 - val_tp: 330.0000 - val_precision: 0.0121 - val_recall: 0.8871\n",
      "Epoch 7/10\n",
      "823084/823084 - 53s - loss: 6.4778e-07 - fn: 127.0000 - fp: 112192.0000 - tn: 709406.0000 - tp: 1359.0000 - precision: 0.0120 - recall: 0.9145 - val_loss: 0.2670 - val_fn: 51.0000 - val_fp: 23644.0000 - val_tn: 181755.0000 - val_tp: 321.0000 - val_precision: 0.0134 - val_recall: 0.8629\n",
      "Epoch 8/10\n",
      "823084/823084 - 56s - loss: 6.5722e-07 - fn: 122.0000 - fp: 110963.0000 - tn: 710635.0000 - tp: 1364.0000 - precision: 0.0121 - recall: 0.9179 - val_loss: 0.3315 - val_fn: 35.0000 - val_fp: 31258.0000 - val_tn: 174141.0000 - val_tp: 337.0000 - val_precision: 0.0107 - val_recall: 0.9059\n",
      "Epoch 9/10\n",
      "823084/823084 - 52s - loss: 6.5293e-07 - fn: 132.0000 - fp: 110973.0000 - tn: 710625.0000 - tp: 1354.0000 - precision: 0.0121 - recall: 0.9112 - val_loss: 0.2493 - val_fn: 47.0000 - val_fp: 23230.0000 - val_tn: 182169.0000 - val_tp: 325.0000 - val_precision: 0.0138 - val_recall: 0.8737\n",
      "Epoch 10/10\n",
      "823084/823084 - 49s - loss: 6.1479e-07 - fn: 118.0000 - fp: 106297.0000 - tn: 715301.0000 - tp: 1368.0000 - precision: 0.0127 - recall: 0.9206 - val_loss: 0.2658 - val_fn: 49.0000 - val_fp: 23733.0000 - val_tn: 181666.0000 - val_tp: 323.0000 - val_precision: 0.0134 - val_recall: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x1a564fd160>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_whole(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks in Training Set =>  1486 , in CV =>  372\n",
      "SMS in Training Set =>  821598 , in CV =>  205399\n",
      "(1906,)\n",
      "Train on 823084 samples, validate on 205771 samples\n",
      "Epoch 1/10\n",
      "823084/823084 - 38s - loss: 6.3460e-07 - fn: 137.0000 - fp: 106864.0000 - tn: 714734.0000 - tp: 1349.0000 - precision: 0.0125 - recall: 0.9078 - val_loss: 0.2485 - val_fn: 37.0000 - val_fp: 23021.0000 - val_tn: 182378.0000 - val_tp: 335.0000 - val_precision: 0.0143 - val_recall: 0.9005\n",
      "Epoch 2/10\n",
      "823084/823084 - 54s - loss: 6.3031e-07 - fn: 138.0000 - fp: 105908.0000 - tn: 715690.0000 - tp: 1348.0000 - precision: 0.0126 - recall: 0.9071 - val_loss: 0.3275 - val_fn: 28.0000 - val_fp: 30443.0000 - val_tn: 174956.0000 - val_tp: 344.0000 - val_precision: 0.0112 - val_recall: 0.9247\n",
      "Epoch 3/10\n",
      "823084/823084 - 64s - loss: 6.0326e-07 - fn: 123.0000 - fp: 103300.0000 - tn: 718298.0000 - tp: 1363.0000 - precision: 0.0130 - recall: 0.9172 - val_loss: 0.2818 - val_fn: 37.0000 - val_fp: 23961.0000 - val_tn: 181438.0000 - val_tp: 335.0000 - val_precision: 0.0138 - val_recall: 0.9005\n",
      "Epoch 4/10\n",
      "823084/823084 - 53s - loss: 6.0860e-07 - fn: 127.0000 - fp: 105477.0000 - tn: 716121.0000 - tp: 1359.0000 - precision: 0.0127 - recall: 0.9145 - val_loss: 0.2888 - val_fn: 32.0000 - val_fp: 26662.0000 - val_tn: 178737.0000 - val_tp: 340.0000 - val_precision: 0.0126 - val_recall: 0.9140\n",
      "Epoch 5/10\n",
      "823084/823084 - 53s - loss: 5.8494e-07 - fn: 117.0000 - fp: 104055.0000 - tn: 717543.0000 - tp: 1369.0000 - precision: 0.0130 - recall: 0.9213 - val_loss: 0.2875 - val_fn: 34.0000 - val_fp: 27066.0000 - val_tn: 178333.0000 - val_tp: 338.0000 - val_precision: 0.0123 - val_recall: 0.9086\n",
      "Epoch 6/10\n",
      "823084/823084 - 53s - loss: 5.9824e-07 - fn: 126.0000 - fp: 105637.0000 - tn: 715961.0000 - tp: 1360.0000 - precision: 0.0127 - recall: 0.9152 - val_loss: 0.2695 - val_fn: 37.0000 - val_fp: 25590.0000 - val_tn: 179809.0000 - val_tp: 335.0000 - val_precision: 0.0129 - val_recall: 0.9005\n",
      "Epoch 7/10\n",
      "823084/823084 - 51s - loss: 5.9366e-07 - fn: 119.0000 - fp: 104790.0000 - tn: 716808.0000 - tp: 1367.0000 - precision: 0.0129 - recall: 0.9199 - val_loss: 0.2146 - val_fn: 43.0000 - val_fp: 22106.0000 - val_tn: 183293.0000 - val_tp: 329.0000 - val_precision: 0.0147 - val_recall: 0.8844\n",
      "Epoch 8/10\n",
      "823084/823084 - 50s - loss: 5.9723e-07 - fn: 102.0000 - fp: 104417.0000 - tn: 717181.0000 - tp: 1384.0000 - precision: 0.0131 - recall: 0.9314 - val_loss: 0.2299 - val_fn: 43.0000 - val_fp: 22698.0000 - val_tn: 182701.0000 - val_tp: 329.0000 - val_precision: 0.0143 - val_recall: 0.8844\n",
      "Epoch 9/10\n",
      "823084/823084 - 51s - loss: 5.9815e-07 - fn: 123.0000 - fp: 102896.0000 - tn: 718702.0000 - tp: 1363.0000 - precision: 0.0131 - recall: 0.9172 - val_loss: 0.2645 - val_fn: 35.0000 - val_fp: 25257.0000 - val_tn: 180142.0000 - val_tp: 337.0000 - val_precision: 0.0132 - val_recall: 0.9059\n",
      "Epoch 10/10\n",
      "823084/823084 - 50s - loss: 5.7088e-07 - fn: 106.0000 - fp: 101018.0000 - tn: 720580.0000 - tp: 1380.0000 - precision: 0.0135 - recall: 0.9287 - val_loss: 0.2537 - val_fn: 36.0000 - val_fp: 24613.0000 - val_tn: 180786.0000 - val_tp: 336.0000 - val_precision: 0.0135 - val_recall: 0.9032\n"
     ]
    }
   ],
   "source": [
    "model = train_whole(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
